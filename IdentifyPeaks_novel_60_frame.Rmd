---
title: "IdentifyPeaks_novel_60_frame"
author: "Hyun Hwang"
date: "04/24/2020"
output: html_document
---


``` {r}
library(ggplot2)
library(reshape2)
library(tidyverse)
library(dplyr)
library(readxl)
options(stringsAsFactors = FALSE)

source("~/Desktop/Files/1/R/ML_project/Rscripts/2020_ml_github/Rfuncs_HH.r")

```


```{r}
## Load data
fluo4_data_novel <- read.csv("~/Desktop/Files/1/R/Calcium_imaging/After_sorting/112119_Lemon/112119_ca0_1.csv")
rownames(fluo4_data_novel) = fluo4_data_novel$Well

```


### Plot the data
```{r}
pdf("~/Desktop/Files/1/R/ML_project/Results/Intensity_plot_novel.pdf")
Cell_list = sort(unique(fluo4_data_novel$Well))
for(cell in Cell_list){
  tempnovel = fluo4_data_novel[fluo4_data_novel$Well == cell, ]
  plot_data_novel = melt(tempnovel[, ])
  p = ggplot(plot_data_novel, aes(x = variable, y = value, group = cell)) + 
            ylab("Intensity") +
            geom_line() + 
            # geom_smooth(data = plot_data_160, method = "loess", se = FALSE, span = 0.037) +
            facet_wrap(~cell_id, scales = "free_y") + 
            scale_x_discrete(name = "Frame", 
                             breaks = c("Frame1", "Frame20", "Frame40", "Frame60"), 
                             labels = c(1, 20, 40, 60))
  print(p)
}
dev.off()
```


### Peak detection
```{r}
x = 1:60
# i = 1

peak_df = data.frame(cell_id = NULL, peak_id = NULL, left = NULL, max = NULL, right = NULL)

pdf("~/Desktop/Files/1/R/ML_project/Results/Peak_plot_novel.pdf")
for(i in 1:54){
  cell_id = unlist( fluo4_data_novel$Well[i] )
  # print(cell_id)
  y = unlist( fluo4_data_novel[i, -(1:2)] )

  peaks = detect_peak(x, y, tup = 30, rtup = 2)
  
  # Remove noises and first peak with s < 5 and A_l < 0.5 * A_r
  if(! is.null(peaks)){
    n_peaks = nrow(peaks)
    
    # Average amplitude
    A_peaks = y[peaks$max] - (y[peaks$left] + y[peaks$right])/2
    
    noise = rep(FALSE, n_peaks)
    for(k in 1:n_peaks){
      if(k == 1){
        A_l = y[peaks$max[k]] - y[peaks$left[k]]
        A_r = y[peaks$max[k]] - y[peaks$right[k]]
        if( (peaks$left[k] < 5) & (A_l < 0.5 * A_r) ){
          noise[k] = TRUE
        }
      }
      if(A_peaks[k] < max(A_peaks) * 0.15 ){
        noise[k] = TRUE
      }
    }
    peaks = peaks[!noise, ]
    n_peaks = nrow(peaks)
    
    p = ggplot(data = data.frame(x = x, y = y), 
      aes(x = x, y = y)) + 
      geom_line(size = 1) + 
      # geom_smooth(method = "loess", se = FALSE, span = 0.039) +
      geom_point(data = data.frame(x = c(peaks$left, peaks$right, peaks$max), y = y[c(peaks$left, peaks$right, peaks$max)], peak = c(rep("S", 2* n_peaks), rep("M", n_peaks))), 
      mapping = aes(x = x, y = y, colour = peak), size = 2) +
      annotate("text", x = peaks$max, y = y[peaks$max]*1.01, label = paste0("peak", 1:n_peaks)) +
      labs(title = cell_id, x = NULL, y = NULL)  +
      theme(text = element_text(size = 20), legend.position = "none")
    
    peak_df = rbind(peak_df, data.frame(cell_id = rep(cell_id, n_peaks), peak_id = paste0("peak", 1:n_peaks), peaks))
  
  }else{
    p = ggplot(data = data.frame(x = x, y = y), 
      aes(x = x, y = y)) + 
      geom_line(size = 1) + 
      # geom_smooth(method = "loess", se = FALSE, span = 0.039) +
      labs(title = cell_id, x = NULL, y = NULL) +
      theme(text = element_text(size = 20), legend.position = "none")
  }
  print(p)
  
}
dev.off()

```

### Before irregular phase assessment - adding 'Time' and 'Time_median' variables to peak_df
```{r}
#phase_df = NULL # data.frame(cellid = NULL, peakid = NULL, time = NULL, time_median = NULL)
Peak_distance = NULL
Peak_distance_median = NULL
peak_distance = NULL
peak_distance_median = NULL

# select 3 columns from peak_amp_df to make dataframe 'phase' 
phase = dplyr::select(peak_df, cell_id, peak_id, max)

# run for-loop to obtain column 'time' per unique cell
for (cellid in unique(phase$cell_id)) {
  #cellid = "0_1"
  peak_distance = NULL
  phase_n = filter(phase, cell_id == cellid) # filter out a unique cell from dataframe 'phase' 
  peak_n = sum(phase_n$cell_id == cellid) # number of peaks from a cell 
  
  if(peak_n == 1){
    peak_distance = 0
  }else{
    for (i in 1:peak_n) {
      if (i == 1) {
        peak_distance[i] <- phase_n$max[i+1] - phase_n$max[i]
      } else {
        peak_distance[i] <- phase_n$max[i] - phase_n$max[i-1]
      }
    }
  }
  #print(time)
  peak_distance_median = median(unlist(peak_distance), na.rm=TRUE)
  peak_distance_median = rep(peak_distance_median, peak_n)
  #print(time_median)
  Peak_distance_median = c(Peak_distance_median, peak_distance_median)
  Peak_distance = c(Peak_distance, peak_distance)
}

phase = cbind(phase, Peak_distance, Peak_distance_median)
#print(phase)
#phase = select(phase, Time, Time_median)

peak_df = cbind(peak_df, dplyr::select(phase, Peak_distance, Peak_distance_median))

```


### Removal of single peak data
```{r}

length(unique(peak_df$cell_id))
# 54


# identify cells with only one peak 
unique_cell_count <- peak_df %>% group_by(cell_id) %>% count(cell_id)
single_peak_cells <- unique_cell_count[ which(unique_cell_count$n == 1) , 1]


# removal of single_peak_cells from peak_df
#filter(peak_df, !(cell_id %in% c(single_peak_cells$cell_id)))
peak_df <- filter(peak_df, !(cell_id %in% c(single_peak_cells$cell_id)))
peak_amp_df <- filter(peak_df, !(cell_id %in% c(single_peak_cells$cell_id)))
length(unique(peak_df$cell_id))
# 54

```


### Identify abnormal peaks by analytic method
- irregular phase assessment and checking amplitude and asymmetry. 
- w/o irregular phase: 8090 normal, 20015 abnormal
- w/ irregular phase: 628 normal, 27477 abnormal 
- after modification: 8731 normal, 19373 abnormal 
```{r}
write.csv(peak_df, file = "~/Desktop/Files/1/R/ML_project/Results/peak_info_novel.csv")


x = 1:60
peak_df <- read_csv("~/Desktop/Files/1/R/ML_project/Results/peak_info_novel.csv", col_types = cols(X1 = col_skip())) %>% dplyr::select(c(cell_id, peak_id, left, max, right, Peak_distance, Peak_distance_median)) %>% as.data.frame


N_peaks = nrow(peak_df)
peak_df$peak_status_analytical_algorithm = "normal" # not yet
peak_var_df = NULL


for (cell_id in peak_df$cell_id) {
  #cell_id = "0_1"
  n_peak = sum(peak_df$cell_id == cell_id)
  i = which(peak_df$cell_id == cell_id)
  
  if(n_peak > 0){
    y = unlist( fluo4_data_novel[cell_id, -(1:2)] )
    sub_peak_df = peak_df[peak_df$cell_id == cell_id, ]
    peak_vars = get_peak_var(x, y, sub_peak_df[, c("left", "max", "right")])

    peak_vars$cell_id = cell_id
    peak_vars$peak_id = paste0("peak", 1:n_peak)
    peak_var_df = rbind(peak_var_df, peak_vars) # save peak variables
    
    A_max = apply(peak_vars[, c("A_l", "A_r")], 1, max)
    A_min = apply(peak_vars[, c("A_l", "A_r")], 1, min)
    A_avg = mean(A_max)
    
    
    ## Irregular Phase assessment 
    # consider peaks that have not exhibited any other anomalies, except the peaks that exhibit double peak anomaly which are treated as a single peak that has the mean of the positions of double peaks as its reference value. Treating a double peak as a single peak prevents the overlap of irregularity and double peak anomaly. 
    # distance of the peaks differs by a user-defined percentage (e.g. 90%) from the median of the peak distances. 
    ud = 0.9 # user-defined percentage 
    for (k in 1:n_peak) {
      if ( (sub_peak_df$Peak_distance[k] < (1 - ud) * sub_peak_df$Peak_distance_median[k]) | (sub_peak_df$Peak_distance[k] > (1 + ud) * sub_peak_df$Peak_distance_median[k]) ) {
        sub_peak_df$peak_status_analytical_algorithm[k] = "abnormal"
        }
      }
    
    
    ## Assess peaks by amplitude
    if(A_max[1] < 0.5 * A_avg){
      sub_peak_df$peak_status_analytical_algorithm[1] = "abnormal"
    }
    for(k in 2:n_peak){
      if( (sub_peak_df$peak_status_analytical_algorithm[k-1] == "abnormal") & (A_max[k] < 0.5 * A_avg) ){
          sub_peak_df$peak_status_analytical_algorithm[k] = "abnormal"
        } else if( (sub_peak_df$peak_status_analytical_algorithm[k-1] == "normal") & (A_max[k] < 0.5 * A_max[k-1]) ){
          sub_peak_df$peak_status_analytical_algorithm[k] = "abnormal"
      }
    }
    
    
    ## Assess peaks by asymmetry
    for(k in 1:n_peak){
      if( (sub_peak_df$peak_status_analytical_algorithm[k] == "normal") & (A_min[k] < 0.80 * A_max[k]) ) {
          sub_peak_df$peak_status_analytical_algorithm[k] = "abnormal"
        }
    }
    
    
    # update peak status
    peak_df$peak_status_analytical_algorithm[peak_df$cell_id == cell_id] = sub_peak_df$peak_status_analytical_algorithm
  }
}

peak_info_df = merge(peak_df, peak_var_df, by = c("cell_id", "peak_id"), sort = FALSE)
peak_info_df <- peak_info_df %>% mutate(cell_peak = paste(peak_info_df$cell_id, peak_info_df$peak_id, sep = ":"))
peak_info_df = peak_info_df %>% distinct(cell_peak, .keep_all = TRUE)
peak_info_df = peak_info_df[, -c(22)]

table(peak_info_df$peak_status_analytical_algorithm)
#abnormal   normal 
#     124      330

head(peak_info_df)

```


### Identify normal/abnormal cells based on identified abnormal peaks
```{r}
cell_status_df = fluo4_data_novel[, c(2,3)]
names(cell_status_df)[1] <- paste("cell_id")
names(cell_status_df)[2] <- paste("cell_status_analytical_algorithm")
cell_status_df[,"cell_status_analytical_algorithm"] <- NA
cell_status_df$cell_status_analytical_algorithm = "normal"

for(i in 1:nrow(cell_status_df)){
  cell_id = cell_status_df$cell_id[i]
  peak_status_analytical_algorithm = peak_info_df$peak_status_analytical_algorithm[peak_info_df$cell_id == cell_id]
  if(length(peak_status_analytical_algorithm) == 0){
    cell_status_df$cell_status_analytical_algorithm[i] = "abnormal"
  }
  else if("abnormal" %in% peak_status_analytical_algorithm){
    cell_status_df$cell_status_analytical_algorithm[i] = "abnormal"
  }
}


cell_status_df <- filter(cell_status_df, !(cell_id %in% c(single_peak_cells$cell_id)))
table(cell_status_df$cell_status_analytical_algorithm)
#abnormal   normal 
#      71       21 

```

### Write results into csv files
```{r}
# update peak status
peak_info_df$cell_peak_id = paste(peak_info_df$cell_id, peak_info_df$peak_id, sep = ":")
peak_info_df = peak_info_df %>% distinct(cell_peak_id, .keep_all = TRUE)
write.csv(peak_info_df, file = "~/Desktop/Files/1/R/ML_project/Results/peak_info_novel.csv")

write.csv(cell_status_df[, ], file = "~/Desktop/Files/1/R/ML_project/Results/cell_status_df_novel.csv")

# colnames(fluo4_data_novel)[2] = "status_by_expert0"
fluo4_data_novel <- read.csv("~/Desktop/Files/1/R/Calcium_imaging/After_sorting/112119_Lemon/112119_ca0_1.csv")
fluo4_data_novel <- fluo4_data_novel[, -c(1)]
names(fluo4_data_novel)[1] <- paste("cell_id")
data_with_status = merge(cell_status_df, fluo4_data_novel, by = c("cell_id"))
data_with_status = data_with_status %>% distinct(cell_id, .keep_all = TRUE)


write.csv(data_with_status, file = "~/Desktop/Files/1/R/ML_project/Results/data_with_status_novel.csv")
```

### Plot signals with status and cell_status_analytical_algorithm
```{r}
pdf("~/Desktop/Files/1/R/ML_project/Results/Signals_with_status_novel.pdf")
Cell_list = sort(unique(data_with_status$cell_id))
for(c in Cell_list){
  tempnovel = data_with_status[ data_with_status$cell_id == c, ]
  plot_data_novel = melt(tempnovel)
  plot_data_novel$Status = factor((plot_data_novel$cell_status_analytical_algorithm), 
                            levels = c("abnormal", "normal"))
  p = ggplot(plot_data_novel, aes(x = variable, y = value, 
                            group = cell_id, 
                            color = cell_status_analytical_algorithm)) + 
    ylab("Intensity") +
   geom_line() + facet_wrap(~cell_id, scales = "free_y") + 
    guides(color = guide_legend(title="cell_status_analytical_algorithm")) +
   scale_x_discrete(name = "Frame", 
                   breaks = c("Frame1", "Frame20", "Frame40", "Frame60"), 
                   labels = c(1, 20, 40, 60))
  print(p)
}
dev.off()
```

