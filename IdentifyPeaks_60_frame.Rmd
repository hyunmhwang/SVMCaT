---
title: "IdentifyPeaks_60_frame"
author: "Hyun Hwang"
date: "04/24/2020"
output:
  html_document:
    df_print: paged
---


``` {r}
library(ggplot2)
library(reshape2)
library(tidyverse)
library(dplyr)
options(stringsAsFactors = FALSE)

source("~/Desktop/Files/1/R/ML_project/Rscripts/2020_ml_github/Rfuncs_HH.r")
```


```{r}
## Load data
fluo4_data <- read.csv("~/Desktop/Files/1/R/ML_project/Data/fluo4_transformed_July2019.csv")
rownames(fluo4_data) = fluo4_data$cell_id

# Status by expert
table(fluo4_data$Status)
#abnormal   normal 
#  33   45 
```


### Plot the data
```{r}
pdf("~/Desktop/Files/1/R/ML_project/Results/Intensity_plot.pdf")
Lane_list = sort(unique(fluo4_data$Lane))
for(lane in Lane_list){
  temp = fluo4_data[fluo4_data$Lane == lane, ]
  plot_data = melt(temp[, -(3:4)])
  p = ggplot(plot_data, aes(x = variable, y = value, group = cell_id, col = Status)) + ylab("Intensity") +
            geom_line() + facet_wrap(~cell_id, scales = "free_y") + 
            scale_x_discrete(name = "Frame", 
                             breaks = c("Frame1", "Frame20", "Frame40", "Frame60"), 
                             labels = c(1, 20, 40, 60))
  print(p)
}
dev.off()
```


### Peak detection
```{r}
x = 1:60
# i = 1

peak_df = data.frame(cell_id = NULL, peak_id = NULL, left = NULL, max = NULL, right = NULL)

pdf("~/Desktop/Files/1/R/ML_project/Results/Peak_plot.pdf")
for(i in 1:78){
  cell_id = unlist( fluo4_data$cell_id[i] )
  # print(cell_id)
  y = unlist( fluo4_data[i, -(1:4)] )
  
  peaks = detect_peak(x, y, tup = 30, rtup = 2)
  
  # Remove noises and first peak with s < 5 and A_l < 0.5 * A_r
  if(! is.null(peaks)){
    n_peaks = nrow(peaks)
    # Average amplitude
    A_peaks = y[peaks$max] - (y[peaks$left] + y[peaks$right])/2
    
    noise = rep(FALSE, n_peaks)
    for(k in 1:n_peaks){
      if(k == 1){
        A_l = y[peaks$max[k]] - y[peaks$left[k]]
        A_r = y[peaks$max[k]] - y[peaks$right[k]]
        if( (peaks$left[k] < 5) & (A_l < 0.5 * A_r) ){
          noise[k] = TRUE
        }
      }
      if(A_peaks[k] < max(A_peaks) * 0.15 ){
        noise[k] = TRUE
      }
    }
    peaks = peaks[!noise, ]
    n_peaks = nrow(peaks)
    
    p = ggplot(data = data.frame(x = x, y = y), 
      aes(x = x, y = y)) + 
      geom_line(size = 1) + 
      # geom_smooth(method = "loess", se = FALSE, span = 0.039) +
      geom_point(data = data.frame(x = c(peaks$left, peaks$right, peaks$max), y = y[c(peaks$left, peaks$right, peaks$max)], peak = c(rep("S", 2* n_peaks), rep("M", n_peaks))), 
      mapping = aes(x = x, y = y, colour = peak), size = 2) +
      annotate("text", x = peaks$max, y = y[peaks$max]*1.01, label = paste0("peak", 1:n_peaks)) +
      labs(title = cell_id, x = NULL, y = NULL)  +
      theme(text = element_text(size = 20), legend.position = "none")
    
    peak_df = rbind(peak_df, data.frame(cell_id = rep(cell_id, n_peaks), peak_id = paste0("peak", 1:n_peaks), peaks))
  
  }else{
    p = ggplot(data = data.frame(x = x, y = y), 
      aes(x = x, y = y)) + 
      geom_line(size = 1) + 
      # geom_smooth(method = "loess", se = FALSE, span = 0.039) +
      labs(title = cell_id, x = NULL, y = NULL) +
      theme(text = element_text(size = 20), legend.position = "none")
  }
  print(p)
  
}
dev.off()

```

### Before irregular phase assessment - adding 'Time' and 'Time_median' variables to peak_df
```{r}
#phase_df = NULL # data.frame(cellid = NULL, peakid = NULL, time = NULL, time_median = NULL)
Peak_distance = NULL
Peak_distance_median = NULL
peak_distance = NULL
peak_distance_median = NULL

# select 3 columns from peak_amp_df to make dataframe 'phase' 
phase = peak_df %>% dplyr::select(cell_id, peak_id, max)

# run for-loop to obtain column 'time' per unique cell
for (cellid in unique(phase$cell_id)) {
  #cellid = "0_1"
  peak_distance = NULL
  phase_n = filter(phase, cell_id == cellid) # filter out a unique cell from dataframe 'phase' 
  peak_n = sum(phase_n$cell_id == cellid) # number of peaks from a cell 
  
  if(peak_n == 1){
    peak_distance = 0
  }else{
    for (i in 1:peak_n) {
      if (i == 1) {
        peak_distance[i] <- phase_n$max[i+1] - phase_n$max[i]
      } else {
        peak_distance[i] <- phase_n$max[i] - phase_n$max[i-1]
      }
    }
  }
  #print(time)
  peak_distance_median = median(unlist(peak_distance), na.rm=TRUE)
  peak_distance_median = rep(peak_distance_median, peak_n)
  #print(time_median)
  Peak_distance_median = c(Peak_distance_median, peak_distance_median)
  Peak_distance = c(Peak_distance, peak_distance)
}

phase = cbind(phase, Peak_distance, Peak_distance_median)
#print(phase)
#phase = select(phase, Time, Time_median)

peak_df = cbind(peak_df, dplyr::select(phase, Peak_distance, Peak_distance_median))

```


### Removal of single peak data
```{r}

length(unique(peak_df$cell_id))
# 77

# identify cells with only one peak 
unique_cell_count <- peak_df %>% group_by(cell_id) %>% count(cell_id)
single_peak_cells <- unique_cell_count[ which(unique_cell_count$n == 1) , 1]


# removal of single_peak_cells from peak_df
#filter(peak_df, !(cell_id %in% c(single_peak_cells$cell_id)))
peak_df <- filter(peak_df, !(cell_id %in% c(single_peak_cells$cell_id)))
peak_amp_df <- filter(peak_df, !(cell_id %in% c(single_peak_cells$cell_id)))
length(unique(peak_df$cell_id))
# 66

```


### Identify abnormal peaks by analytic method
- irregular phase assessment and checking amplitude and asymmetry. 
- 1240 normal, 555 abnormal 
```{r}
write.csv(peak_df, file = "~/Desktop/Files/1/R/ML_project/Results/peak_info.csv")


x = 1:60
peak_df <- read_csv("~/Desktop/Files/1/R/ML_project/Results/peak_info.csv", col_types = cols(X1 = col_skip())) %>% dplyr::select(c(cell_id, peak_id, left, max, right, Peak_distance, Peak_distance_median)) %>% as.data.frame


N_peaks = nrow(peak_df)
peak_df$peak_status_analytical_algorithm = "normal" # not yet
peak_var_df = NULL


for (cell_id in peak_df$cell_id) {
  #cell_id = "32"
  n_peak = sum(peak_df$cell_id == cell_id)
  i = which(peak_df$cell_id == cell_id)
  
  if(n_peak > 0){
    y = unlist( fluo4_data[cell_id, -(1:4)] )
    sub_peak_df = peak_df[peak_df$cell_id == cell_id, ]
    peak_vars = get_peak_var(x, y, sub_peak_df[, c("left", "max", "right")])

    peak_vars$cell_id = cell_id
    peak_vars$peak_id = paste0("peak", 1:n_peak)
    peak_var_df = rbind(peak_var_df, peak_vars) # save peak variables
    
    A_max = apply(peak_vars[, c("A_l", "A_r")], 1, max)
    A_min = apply(peak_vars[, c("A_l", "A_r")], 1, min)
    A_avg = mean(A_max)
    
    
    ## Irregular Phase assessment 
    # consider peaks that have not exhibited any other anomalies, except the peaks that exhibit double peak anomaly which are treated as a single peak that has the mean of the positions of double peaks as its reference value. Treating a double peak as a single peak prevents the overlap of irregularity and double peak anomaly. 
    # distance of the peaks differs by a user-defined percentage (e.g. 90%) from the median of the peak distances. 
    ud = 0.9 # user-defined percentage 
    for (k in 1:n_peak) {
      if ( (sub_peak_df$Peak_distance[k] < (1 - ud) * sub_peak_df$Peak_distance_median[k]) | (sub_peak_df$Peak_distance[k] > (1 + ud) * sub_peak_df$Peak_distance_median[k]) ) {
        sub_peak_df$peak_status_analytical_algorithm[k] = "abnormal"
        }
      }
    
    
    ## Assess peaks by amplitude
    if(A_max[1] < 0.5 * A_avg){
      sub_peak_df$peak_status_analytical_algorithm[1] = "abnormal"
    }
    for(k in 2:n_peak){
        if( (sub_peak_df$peak_status_analytical_algorithm[k-1] == "abnormal") & (A_max[k] < 0.5 * A_avg) ) {
            sub_peak_df$peak_status_analytical_algorithm[k] = "abnormal"
        } else if( (sub_peak_df$peak_status_analytical_algorithm[k-1] == "normal") & (A_max[k] < 0.5 * A_max[k-1]) ){
            sub_peak_df$peak_status_analytical_algorithm[k] = "abnormal"
      }
    }
    
    
    ## Assess peaks by asymmetry
    for(k in 1:n_peak){
      if( (sub_peak_df$peak_status_analytical_algorithm[k] == "normal") & (A_min[k] < 0.80 * A_max[k]) ) {
          sub_peak_df$peak_status_analytical_algorithm[k] = "abnormal"
        }
    }
    
    
    # update peak status
    peak_df$peak_status_analytical_algorithm[peak_df$cell_id == cell_id] = sub_peak_df$peak_status_analytical_algorithm
  }
}


peak_info_df = merge(peak_df, peak_var_df, by = c("cell_id", "peak_id"), sort = FALSE)
table(peak_info_df$peak_status_analytical_algorithm)
#abnormal   normal 
#     555     1240 
head(peak_info_df)

```


### Identify normal/abnormal cells based on identified abnormal peaks
- 30 normal, 48 abnormal 
# after single_peak_cells removal:
abnormal 36, normal 31
```{r}
cell_status_df = fluo4_data[, 1:2]
cell_status_df$cell_status_analytical_algorithm = "normal"

for(i in 1:nrow(cell_status_df)){
  cell_id = cell_status_df$cell_id[i]
  peak_status_analytical_algorithm = peak_info_df$peak_status_analytical_algorithm[peak_info_df$cell_id == cell_id]
  if(length(peak_status_analytical_algorithm) == 0){
    cell_status_df$cell_status_analytical_algorithm[i] = "abnormal"
  }
  else if("abnormal" %in% peak_status_analytical_algorithm){
    cell_status_df$cell_status_analytical_algorithm[i] = "abnormal"
  }
}

cell_status_df <- filter(cell_status_df, !(cell_id %in% c(single_peak_cells$cell_id)))
table(cell_status_df$cell_status_analytical_algorithm)
#abnormal   normal 
#      36       31 

```


### Write results into csv files
```{r}
# update peak status
peak_info_df$cell_peak_id = paste(peak_info_df$cell_id, peak_info_df$peak_id, sep = ":")
peak_info_df = peak_info_df %>% distinct(cell_peak_id, .keep_all = TRUE)
write.csv(peak_info_df, file = "~/Desktop/Files/1/R/ML_project/Results/peak_info.csv")

write.csv(cell_status_df[, -2], file = "~/Desktop/Files/1/R/ML_project/Results/cell_status_df.csv")

colnames(fluo4_data)[2] = "status_by_expert0"
data_with_status = merge(cell_status_df[, -2], fluo4_data, by = c("cell_id"))

write.csv(data_with_status, file = "~/Desktop/Files/1/R/ML_project/Results/data_with_status.csv")
```


### Plot signals with status and cell_status_analytical_algorithm
```{r}
pdf("~/Desktop/Files/1/R/ML_project/Results/Signals_with_status.pdf")
Lane_list = sort(unique(data_with_status$Lane))
for(lane in Lane_list){
  temp = data_with_status[data_with_status$Lane == lane, ]
  plot_data = melt(temp[, -(4:5)])
  plot_data$Status = factor(paste(plot_data$status_by_expert0, plot_data$cell_status_analytical_algorithm, sep = ":"), 
                            levels = c("abnormal:abnormal", "abnormal:normal", "normal:normal", "normal:abnormal"))
  p = ggplot(plot_data, aes(x = variable, y = value, 
                            group = cell_id, 
                            color = Status)) + 
    ylab("Intensity") +
   geom_line() + facet_wrap(~cell_id, scales = "free_y") + 
    guides(color = guide_legend(title="Status:cell_status_analytical_algorithm")) +
   scale_x_discrete(name = "Frame", 
                   breaks = c("Frame1", "Frame20", "Frame40", "Frame60"), 
                   labels = c(1, 20, 40, 60))
  print(p)
}
dev.off()
```


### Plot first and second derivatives of cell "B3_1"
```{r}
fluo4_60 <- read.csv("~/Desktop/Files/1/R/ML_project/Data/fluo4_transformed_July2019.csv")
cellb3_1 <- fluo4_60 %>% filter(cell_id == "B3_1")
cellb3_1 <- cellb3_1[,-(1:4)]

cellb3_1x <- 1:60
cellb3_1y <- cellb3_1
cellb3_1dy <- as.numeric(finite.differences(cellb3_1x, cellb3_1y))
cellb3_1d2y <- finite.differences(cellb3_1x, cellb3_1dy)

png(filename = "~/Desktop/Files/1/R/ML_project/B3_1 Peak 1")
plot(cellb3_1x[1:17], cellb3_1y[1:17], 
     type="l", 
     main = "B3_1 Peak 1")
dev.off()

png(filename = "~/Desktop/Files/1/R/ML_project/B3_1 first derivative")
plot(cellb3_1x, cellb3_1dy, 
     type="l", 
     main = "B3_1 first derivative")
dev.off()

png(filename = "~/Desktop/Files/1/R/ML_project/B3_1 second derivative")
plot(cellb3_1x, cellb3_1d2y, 
     type="l", 
     main = "B3_1 second derivative")
dev.off()

```

