---
title: "IdentifyPeaks_160_frame"
author: "Hyun Hwang"
date: "04/24/2020"
output:
  html_document:
    df_print: paged
---

``` {r}
library(ggplot2)
library(reshape2)
library(tidyverse)
library(dplyr)
library(readxl)
options(stringsAsFactors = FALSE)

source("~/Desktop/Files/1/R/ML_project/Rscripts/2020_ml_github/Rfuncs_HH.r")
```


```{r}
## Load data
fluo4_data_160 <- read_excel("~/Desktop/Files/1/R/ML_project/Data/191003_fluo4.xlsx")
rownames(fluo4_data_160) = fluo4_data_160$cell_id

# Status by expert
table(fluo4_data_160$Status)
# abnormal normal 
#  84   51 
```


### Plot the data
```{r}
pdf("~/Desktop/Files/1/R/ML_project/Results/Intensity_plot_160.pdf")
Cell_list = sort(unique(fluo4_data_160$Cell))
for(cell in Cell_list){
  temp160 = fluo4_data_160[fluo4_data_160$Cell == cell, ]
  plot_data_160 = melt(temp160[, -(2)])
  p = ggplot(plot_data_160, aes(x = variable, y = value, group = cell, col = Status)) + 
            ylab("Intensity") +
            geom_line() + 
            # geom_smooth(data = plot_data_160, method = "loess", se = FALSE, span = 0.037) +
            facet_wrap(~cell_id, scales = "free_y") + 
            scale_x_discrete(name = "Frame", 
                             breaks = c("Frame1", "Frame80", "Frame160"), 
                             labels = c(1, 80, 160))
  print(p)
}
dev.off()
```


### Peak detection
```{r}
x = 1:160
# i = 1

peak_df = data.frame(cell_id = NULL, peak_id = NULL, left = NULL, max = NULL, right = NULL)

pdf("~/Desktop/Files/1/R/ML_project/Results/Peak_plot_160.pdf")
for(i in 1:135){
  cell_id = unlist( fluo4_data_160$cell_id[i] )
  # print(cell_id)
  y = unlist( fluo4_data_160[i, -(1:3)] )
  
  peaks = detect_peak(x, y, tup = 30, rtup = 2)
  
  # Remove noises and first peak with s < 5 and A_l < 0.5 * A_r
  if(! is.null(peaks)){
    n_peaks = nrow(peaks)
    # Average amplitude
    A_peaks = y[peaks$max] - (y[peaks$left] + y[peaks$right])/2
    
    noise = rep(FALSE, n_peaks)
    for(k in 1:n_peaks){
      if(k == 1){
        A_l = y[peaks$max[k]] - y[peaks$left[k]]
        A_r = y[peaks$max[k]] - y[peaks$right[k]]
        if( (peaks$left[k] < 5) & (A_l < 0.5 * A_r) ){
          noise[k] = TRUE
        }
      }
      if(A_peaks[k] < max(A_peaks) * 0.15 ){
        noise[k] = TRUE
      }
    }
    peaks = peaks[!noise, ]
    n_peaks = nrow(peaks)
    
    p = ggplot(data = data.frame(x = x, y = y), 
      aes(x = x, y = y)) + 
      geom_line(size = 1) + 
      # geom_smooth(method = "loess", se = FALSE, span = 0.039) +
      geom_point(data = data.frame(x = c(peaks$left, peaks$right, peaks$max), y = y[c(peaks$left, peaks$right, peaks$max)], peak = c(rep("S", 2* n_peaks), rep("M", n_peaks))), 
      mapping = aes(x = x, y = y, colour = peak), size = 2) +
      annotate("text", x = peaks$max, y = y[peaks$max]*1.01, label = paste0("peak", 1:n_peaks)) +
      labs(title = cell_id, x = NULL, y = NULL)  +
      theme(text = element_text(size = 20), legend.position = "none")
    
    peak_df = rbind(peak_df, data.frame(cell_id = rep(cell_id, n_peaks), peak_id = paste0("peak", 1:n_peaks), peaks))
  
  }else{
    p = ggplot(data = data.frame(x = x, y = y), 
      aes(x = x, y = y)) + 
      geom_line(size = 1) + 
      # geom_smooth(method = "loess", se = FALSE, span = 0.039) +
      labs(title = cell_id, x = NULL, y = NULL) +
      theme(text = element_text(size = 20), legend.position = "none")
  }
  print(p)
  
}
dev.off()

```


### Before irregular phase assessment - adding 'Time' and 'Time_median' variables to peak_df
```{r}
#phase_df = NULL # data.frame(cellid = NULL, peakid = NULL, time = NULL, time_median = NULL)
Peak_distance = NULL
Peak_distance_median = NULL
peak_distance = NULL
peak_distance_median = NULL

# select 3 columns from peak_amp_df to make dataframe 'phase' 
phase = dplyr::select(peak_df, cell_id, peak_id, max)

# run for-loop to obtain column 'time' per unique cell
for (cellid in unique(phase$cell_id)) {
  #cellid = "0_1"
  peak_distance = NULL
  phase_n = filter(phase, cell_id == cellid) # filter out a unique cell from dataframe 'phase' 
  peak_n = sum(phase_n$cell_id == cellid) # number of peaks from a cell 
  
  if(peak_n == 1){
    peak_distance = 0
  }else{
    for (i in 1:peak_n) {
      if (i == 1) {
        peak_distance[i] <- phase_n$max[i+1] - phase_n$max[i]
      } else {
        peak_distance[i] <- phase_n$max[i] - phase_n$max[i-1]
      }
    }
  }
  #print(time)
  peak_distance_median = median(unlist(peak_distance), na.rm=TRUE)
  peak_distance_median = rep(peak_distance_median, peak_n)
  #print(time_median)
  Peak_distance_median = c(Peak_distance_median, peak_distance_median)
  Peak_distance = c(Peak_distance, peak_distance)
}

phase = cbind(phase, Peak_distance, Peak_distance_median)
#print(phase)
#phase = select(phase, Time, Time_median)

peak_df = cbind(peak_df, dplyr::select(phase, Peak_distance, Peak_distance_median))

```


### Removal of single peak data
```{r}

length(unique(peak_df$cell_id))
# 133

# identify cells with only one peak 
unique_cell_count <- peak_df %>% group_by(cell_id) %>% count(cell_id)
single_peak_cells <- unique_cell_count[ which(unique_cell_count$n == 1) , 1]


# removal of single_peak_cells from peak_df
#filter(peak_df, !(cell_id %in% c(single_peak_cells$cell_id)))
peak_df <- filter(peak_df, !(cell_id %in% c(single_peak_cells$cell_id)))
peak_amp_df <- filter(peak_df, !(cell_id %in% c(single_peak_cells$cell_id)))
length(unique(peak_df$cell_id))
# 132

```


### Identify abnormal peaks by analytic method
- irregular phase assessment and checking amplitude and asymmetry. 
- w/o irregular phase: 8090 normal, 20015 abnormal
- w/ irregular phase: 628 normal, 27477 abnormal 
- after modification: 8731 normal, 19373 abnormal 
```{r}
write.csv(peak_df, file = "~/Desktop/Files/1/R/ML_project/Results/peak_info_160.csv")


x = 1:160
peak_df <- read_csv("~/Desktop/Files/1/R/ML_project/Results/peak_info_160.csv", col_types = cols(X1 = col_skip())) %>% dplyr::select(c(cell_id, peak_id, left, max, right, Peak_distance, Peak_distance_median)) %>% as.data.frame



N_peaks = nrow(peak_df)
peak_df$peak_status_analytical_algorithm = "normal" # not yet
peak_var_df = NULL


for (cell_id in peak_df$cell_id) {
  #cell_id = "0_1"
  n_peak = sum(peak_df$cell_id == cell_id)
  i = which(peak_df$cell_id == cell_id)
  
  if(n_peak > 0){
    y = unlist( fluo4_data_160[cell_id, -(1:3)] )
    sub_peak_df = peak_df[peak_df$cell_id == cell_id, ]
    peak_vars = get_peak_var(x, y, sub_peak_df[, c("left", "max", "right")])

    peak_vars$cell_id = cell_id
    peak_vars$peak_id = paste0("peak", 1:n_peak)
    peak_var_df = rbind(peak_var_df, peak_vars) # save peak variables
    
    A_max = apply(peak_vars[, c("A_l", "A_r")], 1, max)
    A_min = apply(peak_vars[, c("A_l", "A_r")], 1, min)
    A_avg = mean(A_max)
    
    
    ## Irregular Phase assessment 
    # consider peaks that have not exhibited any other anomalies, except the peaks that exhibit double peak anomaly which are treated as a single peak that has the mean of the positions of double peaks as its reference value. Treating a double peak as a single peak prevents the overlap of irregularity and double peak anomaly. 
    # distance of the peaks differs by a user-defined percentage (e.g. 90%) from the median of the peak distances. 
    ud = 0.9 # user-defined percentage 
    for (k in 1:n_peak) {
      if ( (sub_peak_df$Peak_distance[k] < (1 - ud) * sub_peak_df$Peak_distance_median[k]) | (sub_peak_df$Peak_distance[k] > (1 + ud) * sub_peak_df$Peak_distance_median[k]) ) {
        sub_peak_df$peak_status_analytical_algorithm[k] = "abnormal"
        }
      }
    
    
    ## Assess peaks by amplitude
    if(A_max[1] < 0.5 * A_avg){
      sub_peak_df$peak_status_analytical_algorithm[1] = "abnormal"
    }
    for(k in 2:n_peak){
      if( (sub_peak_df$peak_status_analytical_algorithm[k-1] == "abnormal") & (A_max[k] < 0.5 * A_avg) ){
          sub_peak_df$peak_status_analytical_algorithm[k] = "abnormal"
        } else if( (sub_peak_df$peak_status_analytical_algorithm[k-1] == "normal") & (A_max[k] < 0.5 * A_max[k-1]) ){
          sub_peak_df$peak_status_analytical_algorithm[k] = "abnormal"
      }
    }
    
    
    ## Assess peaks by asymmetry
    for(k in 1:n_peak){
      if( (sub_peak_df$peak_status_analytical_algorithm[k] == "normal") & (A_min[k] < 0.80 * A_max[k]) ) {
          sub_peak_df$peak_status_analytical_algorithm[k] = "abnormal"
        }
    }
    
    # update peak status
    peak_df$peak_status_analytical_algorithm[peak_df$cell_id == cell_id] = sub_peak_df$peak_status_analytical_algorithm
  }
}


peak_info_df = merge(peak_df, peak_var_df, by = c("cell_id", "peak_id"), sort = FALSE)
table(peak_info_df$peak_status_analytical_algorithm)
head(peak_info_df)
#abnormal   normal 
#   19373     8731 

```


### Identify normal/abnormal cells based on identified abnormal peaks
- w/ irregular phase: 1 normal, 134 abnormal 
- w/o irregular phase: 49 normal, 86 abnormal
- after modification: 51 normal, 83 abnormal 
```{r}
cell_status_df = fluo4_data_160[, c(1,3)]
cell_status_df$cell_status_analytical_algorithm = "normal"

for(i in 1:nrow(cell_status_df)){
  cell_id = cell_status_df$cell_id[i]
  peak_status_analytical_algorithm = peak_info_df$peak_status_analytical_algorithm[peak_info_df$cell_id == cell_id]
  if(length(peak_status_analytical_algorithm) == 0){
    cell_status_df$cell_status_analytical_algorithm[i] = "abnormal"
  }
  else if("abnormal" %in% peak_status_analytical_algorithm){
    cell_status_df$cell_status_analytical_algorithm[i] = "abnormal"
  }
}


cell_status_df <- filter(cell_status_df, !(cell_id %in% c(single_peak_cells$cell_id)))
table(cell_status_df$cell_status_analytical_algorithm)
#abnormal   normal 

```


### Write results into csv files
```{r}
# update peak status
peak_info_df$cell_peak_id = paste(peak_info_df$cell_id, peak_info_df$peak_id, sep = ":")
peak_info_df = peak_info_df %>% distinct(cell_peak_id, .keep_all = TRUE)
write.csv(peak_info_df, file = "~/Desktop/Files/1/R/ML_project/Results/peak_info_160.csv")

write.csv(cell_status_df[, -2], file = "~/Desktop/Files/1/R/ML_project/Results/cell_status_df_160.csv")

# colnames(fluo4_data_160)[2] = "status_by_expert0"
data_with_status = merge(cell_status_df[, -2], fluo4_data_160, by = c("cell_id"))
write.csv(data_with_status, file = "~/Desktop/Files/1/R/ML_project/Results/data_with_status_160.csv")
```


### Plot signals with status and cell_status_analytical_algorithm
```{r}
pdf("~/Desktop/Files/1/R/ML_project/Results/Signals_with_status_160.pdf")
Cell_list = sort(unique(data_with_status$Cell))
for(cell in Cell_list){
  temp = data_with_status[data_with_status$Cell == cell, ]
  plot_data = melt(temp[, -(3)])
  plot_data$Status = factor(paste(plot_data$Status, plot_data$cell_status_analytical_algorithm, sep = ":"), 
                            levels = c("abnormal:abnormal", "abnormal:normal", "normal:normal", "normal:abnormal"))
  p = ggplot(plot_data, aes(x = variable, y = value, 
                            group = cell_id, 
                            color = Status)) + 
    ylab("Intensity") +
   geom_line() + facet_wrap(~cell_id, scales = "free_y") + 
    guides(color = guide_legend(title="Status:cell_status_analytical_algorithm")) +
   scale_x_discrete(name = "Frame", 
                   breaks = c("Frame1", "Frame80", "Frame160"), 
                   labels = c(1, 80, 160))
  print(p)
}
dev.off()
```

